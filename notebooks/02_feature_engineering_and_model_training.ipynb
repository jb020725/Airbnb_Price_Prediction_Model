{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b679d99f-de0c-4e9e-9497-dac919f56ff6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load Featured Dataset, Prepare Target, and Train-Test Split\n",
    "\n",
    "This notebook cell loads the fully featured Airbnb dataset with all preprocessing done, applies a log-transform to the target price for better modeling behavior, and then splits the data into training and test sets for downstream machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c08773d-00ad-4da8-8ab9-8f09c40e8468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (35436, 18)\n",
      "Test set shape: (8859, 18)\n",
      "Sample features:\n",
      "       host_identity_verified  instant_bookable  construction_year  \\\n",
      "4955                        1                 0             2004.0   \n",
      "23316                       0                 1             2005.0   \n",
      "43055                       0                 0             2021.0   \n",
      "15516                       1                 1             2007.0   \n",
      "11671                       1                 0             2015.0   \n",
      "\n",
      "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
      "4955              1.0                2.0               0.05   \n",
      "23316             1.0               12.0               2.95   \n",
      "43055             1.0               24.0               2.47   \n",
      "15516             1.0               16.0               1.84   \n",
      "11671             1.0                8.0               0.41   \n",
      "\n",
      "       review_rate_number  availability_365  cancellation_policy_moderate  \\\n",
      "4955                  3.0              22.0                          True   \n",
      "23316                 3.0             358.0                         False   \n",
      "43055                 4.0             351.0                         False   \n",
      "15516                 3.0             310.0                         False   \n",
      "11671                 2.0             365.0                          True   \n",
      "\n",
      "       cancellation_policy_strict  room_type_Hotel room  \\\n",
      "4955                        False                 False   \n",
      "23316                        True                 False   \n",
      "43055                        True                 False   \n",
      "15516                        True                 False   \n",
      "11671                       False                 False   \n",
      "\n",
      "       room_type_Private room  room_type_Shared room  last_review_year  \\\n",
      "4955                    False                  False              2016   \n",
      "23316                    True                  False              2022   \n",
      "43055                    True                  False              2019   \n",
      "15516                    True                  False              2019   \n",
      "11671                    True                  False              2017   \n",
      "\n",
      "       last_review_month  days_since_last_review  property_age  \\\n",
      "4955                   1                    3461          21.0   \n",
      "23316                  2                    1219          20.0   \n",
      "43055                  6                    2188           4.0   \n",
      "15516                  6                    2200          18.0   \n",
      "11671                 12                    2741          10.0   \n",
      "\n",
      "       neighbourhood_freq  \n",
      "4955                  836  \n",
      "23316                 362  \n",
      "43055                  76  \n",
      "15516                3541  \n",
      "11671                 534  \n",
      "Sample targets:\n",
      "4955     5.837730\n",
      "23316    6.759255\n",
      "43055    6.466145\n",
      "15516    6.304449\n",
      "11671    5.991465\n",
      "Name: log_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the featured dataset\n",
    "df = pd.read_csv(\"../data/cleaned/airbnb_featured_data.csv\")\n",
    "\n",
    "# Step 2: Prepare target variable\n",
    "# Log-transform 'price' to reduce skewness (common for price prediction)\n",
    "df['log_price'] = np.log1p(df['price'])\n",
    "\n",
    "# Step 3: Define features (drop original price and any non-feature columns)\n",
    "X = df.drop(columns=['price', 'log_price'])  # All features except price\n",
    "y = df['log_price']  # Target variable for training\n",
    "\n",
    "# Step 4: Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Quick sanity checks\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Sample features:\\n{X_train.head()}\")\n",
    "print(f\"Sample targets:\\n{y_train.head()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ce8c6-aeb3-4ba3-9443-3661532d7856",
   "metadata": {},
   "source": [
    "# Baseline Model Training and Evaluation\n",
    "\n",
    "We will train a simple Random Forest Regressor on the prepared dataset to establish a baseline performance. The target variable is the log-transformed price to stabilize variance.\n",
    "\n",
    "**Steps:**\n",
    "- Initialize the Random Forest model with 100 trees and a fixed random state for reproducibility.\n",
    "- Train the model on the training set.\n",
    "- Predict on the test set.\n",
    "- Evaluate the model performance using RMSE (Root Mean Squared Error) and R² score in the log-price scale.\n",
    "- Convert predictions back to the original price scale to interpret error in actual price units.\n",
    "\n",
    "This baseline will help gauge how well the current features predict Airbnb listing prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ea15a3-be0b-4f5f-8b5b-b41a4cb74eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (log scale): 0.6142\n",
      "Test R² score: 0.2975\n",
      "Test RMSE (original price scale): 304.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Train model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate RMSE manually since 'squared' param unsupported\n",
    "rmse_log = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test RMSE (log scale): {rmse_log:.4f}\")\n",
    "print(f\"Test R² score: {r2:.4f}\")\n",
    "\n",
    "# Back to original price scale\n",
    "y_test_price = np.expm1(y_test)\n",
    "y_pred_price = np.expm1(y_pred)\n",
    "rmse_price = mean_squared_error(y_test_price, y_pred_price) ** 0.5\n",
    "\n",
    "print(f\"Test RMSE (original price scale): {rmse_price:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f5bf7-1adb-4c30-a89f-03f83c2f34f0",
   "metadata": {},
   "source": [
    "# Improved Model: XGBoost Regressor\n",
    "\n",
    "We use the XGBoost regressor, a powerful gradient boosting framework that often outperforms Random Forest on structured datasets. This step includes:\n",
    "\n",
    "- Initializing XGBoost with default parameters.\n",
    "- Training on the same training data.\n",
    "- Evaluating performance using RMSE and R² on the test set.\n",
    "- Comparing results with the Random Forest baseline.\n",
    "\n",
    "XGBoost is known for faster training and often better accuracy, especially with some tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56480f26-715e-4e27-9e0a-1d034d42775b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test RMSE (log scale): 0.7072\n",
      "XGBoost Test R² score: 0.0687\n",
      "XGBoost Test RMSE (original price scale): 339.73\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize XGBoost regressor\n",
    "xgb_reg = xgb.XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "# Train\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgb = xgb_reg.predict(X_test)\n",
    "\n",
    "# Evaluate on log scale\n",
    "rmse_log_xgb = mean_squared_error(y_test, y_pred_xgb) ** 0.5\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Test RMSE (log scale): {rmse_log_xgb:.4f}\")\n",
    "print(f\"XGBoost Test R² score: {r2_xgb:.4f}\")\n",
    "\n",
    "# Convert back to original price scale\n",
    "y_test_price = np.expm1(y_test)\n",
    "y_pred_price_xgb = np.expm1(y_pred_xgb)\n",
    "rmse_price_xgb = mean_squared_error(y_test_price, y_pred_price_xgb) ** 0.5\n",
    "\n",
    "print(f\"XGBoost Test RMSE (original price scale): {rmse_price_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1cecd-9449-47df-b840-e8fc5b2230ac",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning: Random Forest Regressor\n",
    "\n",
    "We will optimize key Random Forest hyperparameters to improve performance:\n",
    "\n",
    "- Number of trees (`n_estimators`)\n",
    "- Maximum tree depth (`max_depth`)\n",
    "- Minimum samples per leaf (`min_samples_leaf`)\n",
    "\n",
    "We’ll use randomized search with cross-validation to efficiently explore combinations.\n",
    "\n",
    "This should boost accuracy without much extra complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d13b49-6922-4767-8375-63755229c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best parameters found: {'n_estimators': 500, 'min_samples_leaf': 1, 'max_depth': 40}\n",
      "Tuned RF Test RMSE (log scale): 0.6101\n",
      "Tuned RF Test R² score: 0.3068\n",
      "Tuned RF Test RMSE (original price scale): 302.34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define model\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Hyperparameter space\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run search on training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "\n",
    "rmse_log_tuned = mean_squared_error(y_test, y_pred_tuned) ** 0.5\n",
    "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(f\"Tuned RF Test RMSE (log scale): {rmse_log_tuned:.4f}\")\n",
    "print(f\"Tuned RF Test R² score: {r2_tuned:.4f}\")\n",
    "\n",
    "# Back to original price scale\n",
    "\n",
    "y_test_price = np.expm1(y_test)\n",
    "y_pred_price_tuned = np.expm1(y_pred_tuned)\n",
    "rmse_price_tuned = mean_squared_error(y_test_price, y_pred_price_tuned) ** 0.5\n",
    "\n",
    "print(f\"Tuned RF Test RMSE (original price scale): {rmse_price_tuned:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80f01c-9e1e-4cfb-83f8-710a0421c35b",
   "metadata": {},
   "source": [
    "# Save the Trained Model and Artifacts for Deployment\n",
    "\n",
    "We save the trained Random Forest model and necessary preprocessing info using `joblib`. This ensures we can load the model later for inference without retraining.\n",
    "\n",
    "- Save the trained model object.\n",
    "- Save feature names list (to keep consistent feature order).\n",
    "- Provide loading and prediction example for deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9c1508-a5bd-4fed-9db8-f4f56c277ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models\\random_forest_tuned_model.joblib\n",
      "Feature columns saved to models\\feature_columns.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ensure models directory exists\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "model_path = os.path.join(model_dir, \"random_forest_tuned_model.joblib\")\n",
    "features_path = os.path.join(model_dir, \"feature_columns.joblib\")\n",
    "\n",
    "# Save model and features\n",
    "joblib.dump(best_rf, model_path)\n",
    "joblib.dump(X_train.columns.tolist(), features_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Feature columns saved to {features_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f6a4a1-d1c9-48f0-bd10-a253f4058c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features used in training: 18\n",
      "Features:\n",
      "- host_identity_verified\n",
      "- instant_bookable\n",
      "- construction_year\n",
      "- minimum_nights\n",
      "- number_of_reviews\n",
      "- reviews_per_month\n",
      "- review_rate_number\n",
      "- availability_365\n",
      "- cancellation_policy_moderate\n",
      "- cancellation_policy_strict\n",
      "- room_type_Hotel room\n",
      "- room_type_Private room\n",
      "- room_type_Shared room\n",
      "- last_review_year\n",
      "- last_review_month\n",
      "- days_since_last_review\n",
      "- property_age\n",
      "- neighbourhood_freq\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load feature columns saved during training\n",
    "features_path = \"models/feature_columns.joblib\"\n",
    "feature_cols = joblib.load(features_path)\n",
    "\n",
    "print(f\"Number of features used in training: {len(feature_cols)}\")\n",
    "print(\"Features:\")\n",
    "for f in feature_cols:\n",
    "    print(f\"- {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41253193-8b2c-4223-a9ba-c8ad9e294815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted log price: 6.1678\n",
      "Predicted price: $476.15\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load model and features\n",
    "model_path = \"models/random_forest_tuned_model.joblib\"\n",
    "features_path = \"models/feature_columns.joblib\"\n",
    "model = joblib.load(model_path)\n",
    "feature_cols = joblib.load(features_path)\n",
    "\n",
    "# Create a sample input with plausible random values for each feature\n",
    "sample_data = {\n",
    "    'host_identity_verified': [1],        # binary 0 or 1\n",
    "    'instant_bookable': [1],               # binary 0 or 1\n",
    "    'construction_year': [2015],           # year in float\n",
    "    'minimum_nights': [2],                 # float\n",
    "    'number_of_reviews': [10],             # float\n",
    "    'reviews_per_month': [0.5],            # float\n",
    "    'review_rate_number': [4.0],           # rating 1-5 float\n",
    "    'availability_365': [150],             # float days available in year\n",
    "    'cancellation_policy_moderate': [False], # bool\n",
    "    'cancellation_policy_strict': [True],    # bool\n",
    "    'room_type_Hotel room': [False],          # bool\n",
    "    'room_type_Private room': [True],         # bool\n",
    "    'room_type_Shared room': [False],          # bool\n",
    "    'last_review_year': [2022],               # int\n",
    "    'last_review_month': [5],                  # int\n",
    "    'days_since_last_review': [100],           # int\n",
    "    'property_age': [7],                        # float\n",
    "    'neighbourhood_freq': [500]                 # int\n",
    "}\n",
    "\n",
    "# Build DataFrame with correct feature order\n",
    "X_sample = pd.DataFrame(sample_data)[feature_cols]\n",
    "\n",
    "# Predict log price and convert back to original price scale\n",
    "log_price_pred = model.predict(X_sample)[0]\n",
    "price_pred = np.expm1(log_price_pred)\n",
    "\n",
    "print(f\"Predicted log price: {log_price_pred:.4f}\")\n",
    "print(f\"Predicted price: ${price_pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "706f2068-d7b3-49cc-84fc-a31df2983a1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming your final cleaned DataFrame with both columns is named df_cleaned\u001b[39;00m\n\u001b[0;32m      2\u001b[0m neighbourhood_freq_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mdf_cleaned\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood_freq\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood_freq\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Optional: Save to file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming your final cleaned DataFrame with both columns is named df_cleaned\n",
    "neighbourhood_freq_dict = (\n",
    "    df_cleaned[['neighbourhood', 'neighbourhood_freq']]\n",
    "    .drop_duplicates()\n",
    "    .set_index('neighbourhood')['neighbourhood_freq']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Optional: Save to file\n",
    "import joblib\n",
    "joblib.dump(neighbourhood_freq_dict, \"models/neighbourhood_freq_dict.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a27efa7-37a9-42eb-916a-90b0d32d91fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['neighbourhood'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/cleaned/airbnb_featured_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Extract the neighbourhood → frequency mapping\u001b[39;00m\n\u001b[0;32m      8\u001b[0m neighbourhood_freq_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mdf_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneighbourhood\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneighbourhood_freq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneighbourhood_freq\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Save the dictionary for use in Streamlit\u001b[39;00m\n\u001b[0;32m     16\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(neighbourhood_freq_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/neighbourhood_freq_dict.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Airbnb_Price_Prediction_Model\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\Airbnb_Price_Prediction_Model\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Airbnb_Price_Prediction_Model\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['neighbourhood'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the final featured dataset (make sure the path is correct)\n",
    "df_cleaned = pd.read_csv(\"../data/cleaned/airbnb_featured_data.csv\")\n",
    "\n",
    "# Extract the neighbourhood → frequency mapping\n",
    "neighbourhood_freq_dict = (\n",
    "    df_cleaned[['neighbourhood', 'neighbourhood_freq']]\n",
    "    .drop_duplicates()\n",
    "    .set_index('neighbourhood')['neighbourhood_freq']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Save the dictionary for use in Streamlit\n",
    "joblib.dump(neighbourhood_freq_dict, \"models/neighbourhood_freq_dict.joblib\")\n",
    "\n",
    "print(f\"Saved {len(neighbourhood_freq_dict)} neighbourhoods to models/neighbourhood_freq_dict.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7751d27a-c20c-49df-a2cf-1034fdd45477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['host_identity_verified', 'instant_bookable', 'construction_year', 'price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'review_rate_number', 'availability_365', 'cancellation_policy_moderate', 'cancellation_policy_strict', 'room_type_Hotel room', 'room_type_Private room', 'room_type_Shared room', 'last_review_year', 'last_review_month', 'days_since_last_review', 'property_age', 'neighbourhood_freq']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/cleaned/airbnb_featured_data.csv\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76ed94eb-cdf5-4e0b-9256-eee8291e024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: models/neighbourhood_freq_dict.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load full cleaned dataset BEFORE dropping 'neighbourhood'\n",
    "df_full = pd.read_csv(\"../data/cleaned/airbnb_cleaned.csv\")  # this should have 'neighbourhood' column\n",
    "\n",
    "# Load final featured dataset with neighbourhood_freq\n",
    "df_featured = pd.read_csv(\"../data/cleaned/airbnb_featured_data.csv\")\n",
    "\n",
    "# Merge on unique identifier (index assumed to be consistent)\n",
    "df_full = df_full.reset_index(drop=True)\n",
    "df_featured = df_featured.reset_index(drop=True)\n",
    "df_merged = pd.concat([df_full['neighbourhood'], df_featured['neighbourhood_freq']], axis=1)\n",
    "\n",
    "# Drop duplicates and build mapping\n",
    "neighbourhood_freq_dict = (\n",
    "    df_merged\n",
    "    .drop_duplicates()\n",
    "    .set_index('neighbourhood')['neighbourhood_freq']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Save for Streamlit app\n",
    "joblib.dump(neighbourhood_freq_dict, \"models/neighbourhood_freq_dict.joblib\")\n",
    "print(\"✅ Saved: models/neighbourhood_freq_dict.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6043dc-148f-4ad2-a5cb-25181e5f1d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
